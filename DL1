# 2-layer MNIST classifier 
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
from torchvision import transforms
from torch.utils.data import DataLoader

# 1. Data loading
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.1307,), (0.3081,))  # MNIST mean/std
])

train_dataset = torchvision.datasets.MNIST(root="./data", train=True, download=True, transform=transform)
train_loader  = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2, pin_memory=True)

test_dataset = torchvision.datasets.MNIST(root="./data", train=False, download=True, transform=transform)
test_loader  = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=2, pin_memory=True)

# 2. Model definition
class DigitClassifier(nn.Module):
    def __init__(self):
        super(DigitClassifier, self).__init__()
        # Your network architecture here (784 -> 128 -> 10)
        self.net = nn.Sequential(
            nn.Flatten(),                 # (1,28,28) -> (784)
            nn.Linear(28*28, 128),
            nn.ReLU(inplace=True),
            nn.Linear(128, 10)
            # Note: no Softmax because CrossEntropyLoss expects raw logits
        )

    def forward(self, x):
        # Forward pass logic here
        return self.net(x)

# 3. Training loop
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = DigitClassifier().to(device)
optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)
criterion = nn.CrossEntropyLoss()

def evaluate(loader):
    model.eval()
    correct = 0
    total = 0
    loss_sum = 0.0
    with torch.no_grad():
        for imgs, labels in loader:
            imgs, labels = imgs.to(device), labels.to(device)
            logits = model(imgs)
            loss = criterion(logits, labels)
            loss_sum += loss.item() * imgs.size(0)
            preds = logits.argmax(dim=1)
            correct += (preds == labels).sum().item()
            total += labels.size(0)
    return loss_sum / total, 100.0 * correct / total

EPOCHS = 10
for epoch in range(EPOCHS):
    # Training code here
    model.train()
    running_loss = 0.0
    running_correct = 0
    running_total = 0

    for batch_idx, (imgs, labels) in enumerate(train_loader):
        imgs, labels = imgs.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model(imgs)            # logits
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item() * imgs.size(0)
        preds = outputs.argmax(dim=1)
        running_correct += (preds == labels).sum().item()
        running_total += labels.size(0)

    train_loss = running_loss / running_total
    train_acc  = 100.0 * running_correct / running_total
    test_loss, test_acc = evaluate(test_loader)

    print(f"Epoch {epoch+1}/{EPOCHS} | Train Loss: {train_loss:.4f} Acc: {train_acc:.2f}% | "
          f"Test Loss: {test_loss:.4f} Acc: {test_acc:.2f}%")

# Quick inference demo (same normalization assumed)
def predict_single(img_tensor):
    # img_tensor: 1x28x28 (torch tensor, normalized like train)
    model.eval()
    with torch.no_grad():
        img = img_tensor.unsqueeze(0).to(device)  # -> (1,1,28,28)
        logits = model(img)
        probs = torch.softmax(logits, dim=1)
        conf, pred = probs.max(dim=1)
        return int(pred.item()), float(conf.item())



--------------NEXT CELL-----------------

import torch
import matplotlib.pyplot as plt
from torchvision import datasets, transforms

# Device setup
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Load test dataset
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.1307,), (0.3081,))
])
test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)

# Define function
def predict_and_display(img, model, classes):
    model.eval()
    with torch.no_grad():
        img_tensor = img.unsqueeze(0).to(device)
        logits = model(img_tensor)
        probs = torch.softmax(logits, dim=1)
        confidence, pred_label = torch.max(probs, dim=1)

    # Display image
    plt.imshow(img.squeeze(), cmap='gray')
    plt.title(f"Predicted: {classes[pred_label.item()]} ({confidence.item()*100:.2f}% confidence)")
    plt.axis('off')
    plt.show()

    # Print formatted output
    print("Input: [handwritten digit]")
    print("Output:", [round(p, 2) for p in probs.squeeze().tolist()])
    print(f"Prediction: {classes[pred_label.item()]} ({confidence.item()*100:.0f}% confidence)")

# Example usage
classes = [str(i) for i in range(10)]
img, label = test_dataset[7]  # change index to test other digits
predict_and_display(img, model, classes)


